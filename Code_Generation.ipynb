{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install packages\n",
        "import subprocess\n",
        "subprocess.run(['pip', 'install', 'streamlit', 'pyngrok', '-q'], check=True)\n",
        "\n",
        "# Create app.py file with Groq integration\n",
        "app_code = \"\"\"import streamlit as st\n",
        "import time\n",
        "import requests\n",
        "\n",
        "st.set_page_config(page_title=\"Code Llama Assistant\", page_icon=\"ðŸ¦™\", layout=\"wide\")\n",
        "\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = [{\"role\": \"assistant\", \"content\": \"Hi! I'm powered by Groq AI. Describe what code you need, and I'll generate it for you.\"}]\n",
        "\n",
        "st.title(\"ðŸ¦™ Code Generator with Groq\")\n",
        "st.caption(\"Powered by Groq AI - Free & Fast\")\n",
        "\n",
        "with st.sidebar:\n",
        "    st.header(\"âš™ï¸ Settings\")\n",
        "    st.subheader(\"API Configuration\")\n",
        "    api_key = st.text_input(\"Groq API Key\", type=\"password\", placeholder=\"Paste your Groq API key here\")\n",
        "    st.subheader(\"Model Parameters\")\n",
        "    temperature = st.slider(\"Temperature\", 0.0, 2.0, 0.7, 0.1)\n",
        "    max_tokens = st.slider(\"Max Tokens\", 100, 4000, 2000, 100)\n",
        "    st.divider()\n",
        "    if st.button(\"ðŸ—‘ï¸ Clear Chat\", use_container_width=True):\n",
        "        st.session_state.messages = [{\"role\": \"assistant\", \"content\": \"Hi! I'm powered by Groq AI. Describe what code you need, and I'll generate it for you.\"}]\n",
        "        st.rerun()\n",
        "    st.divider()\n",
        "    st.caption(\"Built for AI Engineers\")\n",
        "\n",
        "for message in st.session_state.messages:\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "        st.markdown(message[\"content\"])\n",
        "\n",
        "def call_groq_api(prompt, api_key, temperature, max_tokens):\n",
        "    if api_key:\n",
        "        try:\n",
        "            headers = {\n",
        "                'Content-Type': 'application/json',\n",
        "                'Authorization': f'Bearer {api_key}'\n",
        "            }\n",
        "            payload = {\n",
        "                'model': 'llama-3.3-70b-versatile',\n",
        "                'messages': [\n",
        "                    {'role': 'system', 'content': 'You are an expert programmer. Generate clean, efficient, and well-commented code based on user requests.'},\n",
        "                    {'role': 'user', 'content': f'Write Python code for: {prompt}'}\n",
        "                ],\n",
        "                'temperature': temperature,\n",
        "                'max_tokens': max_tokens\n",
        "            }\n",
        "            response = requests.post('https://api.groq.com/openai/v1/chat/completions', headers=headers, json=payload, timeout=30)\n",
        "            if response.status_code == 200:\n",
        "                return response.json()['choices'][0]['message']['content']\n",
        "            else:\n",
        "                return f\"âŒ API Error: {response.status_code} - {response.text}\"\n",
        "        except Exception as e:\n",
        "            return f\"âŒ Error: {str(e)}\"\n",
        "    return \"âš ï¸ **Please enter your Groq API key in the sidebar!**\"\n",
        "\n",
        "prompt = st.chat_input(\"Describe the code you need...\")\n",
        "\n",
        "if prompt:\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "    with st.chat_message(\"user\"):\n",
        "        st.markdown(prompt)\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        with st.spinner(\"Generating code...\"):\n",
        "            response = call_groq_api(prompt, api_key, temperature, max_tokens)\n",
        "            st.markdown(response)\n",
        "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
        "\"\"\"\n",
        "\n",
        "with open('app.py', 'w') as f:\n",
        "    f.write(app_code)\n",
        "\n",
        "print(\"âœ… app.py created with Groq integration!\")\n",
        "\n",
        "# Setup ngrok - REPLACE WITH YOUR NGROK TOKEN\n",
        "subprocess.run(['ngrok', 'authtoken', '2zMe0Zk30kz2LtcsrVM5DIrVUGD_uEgcmo27JEHxSAiQzzb4'], check=True)\n",
        "\n",
        "# Run app\n",
        "subprocess.Popen(['streamlit', 'run', 'app.py'])\n",
        "\n",
        "# Create public URL\n",
        "from pyngrok import ngrok\n",
        "import time\n",
        "time.sleep(3)\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"ðŸš€ Your app is live at: {public_url}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIzqfbIOAYiZ",
        "outputId": "c3fb954b-4bd0-4ad2-d537-570df6d5e9cf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… app.py created with Groq integration!\n",
            "ðŸš€ Your app is live at: NgrokTunnel: \"https://171744d3afdc.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}